{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQ1lFV23y0sS",
        "outputId": "628cc39d-f932-4dd6-cb11-2fd1473b4db8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.1-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.1\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JXwZ6twhfBtt"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
        "from transformers import AutoTokenizer, DistilBertModel, AdamW, get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "from sklearn.metrics import classification_report, confusion_matrix, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_dUJEEDtKPu"
      },
      "source": [
        "### Preparing Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vc7-_eHmo2gR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4abf2995-1a7a-4942-e299-f4aa52d1c1d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using GPU:  0\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    # torch.cuda.set_device(0)\n",
        "    device = torch.device('cuda')\n",
        "    print('Using GPU: ', torch.cuda.current_device())\n",
        "else:\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnC0eTl9tMjl"
      },
      "source": [
        "### Useful functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Nw5oEEuo3PR"
      },
      "outputs": [],
      "source": [
        "def get_dataset(df, tokenizer, mode='train'):\n",
        "    sentences, labels = df['comment_text'], df.iloc[:,2:].to_numpy()\n",
        "    max_length = 300\n",
        "    in_T = []\n",
        "    in_T_attn_masks = []\n",
        "    for sentence in sentences:\n",
        "        enc_sent_dict = tokenizer(\n",
        "            sentence[:300],\n",
        "            max_length = max_length,\n",
        "            add_special_tokens = True,\n",
        "            pad_to_max_length = True,\n",
        "            return_attention_mask = True,\n",
        "            return_tensors = 'pt'\n",
        "        )\n",
        "        in_T.append(enc_sent_dict['input_ids'])\n",
        "        in_T_attn_masks.append(enc_sent_dict['attention_mask'])\n",
        "    \n",
        "    in_T = torch.cat(in_T, dim=0)\n",
        "    in_T_attn_masks = torch.cat(in_T_attn_masks, dim=0)\n",
        "    labels = torch.tensor(labels, dtype = torch.float32)\n",
        "    print('Text Input: ' , in_T.shape)\n",
        "    print('Text Input Attention: ' , in_T_attn_masks.shape)    \n",
        "    print('Labels: ' , labels.shape)\n",
        "    \n",
        "    dataset = TensorDataset(\n",
        "        in_T,\n",
        "        in_T_attn_masks,\n",
        "        labels\n",
        "    )\n",
        "    \n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    val_size = len(dataset) - train_size\n",
        "    \n",
        "    train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "    return train_dataset, val_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LskbFR30tRS6"
      },
      "outputs": [],
      "source": [
        "class MultiTaskClassifier(nn.Module):\n",
        "    def __init__(self, hidden_dim, num_labels):\n",
        "        super(MultiTaskClassifier, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.num_labels = num_labels\n",
        "        \n",
        "        self.bertmodel = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "        self.ffn1 = nn.Linear(768, hidden_dim)\n",
        "        self.dp1 = nn.Dropout()\n",
        "        self.ffn2 = nn.Linear(hidden_dim, num_labels)\n",
        "        \n",
        "    def forward(self, in_T, in_T_attn_masks):\n",
        "        hidden_states = self.bertmodel(in_T, in_T_attn_masks).last_hidden_state\n",
        "        x = torch.mean(hidden_states, dim=1)\n",
        "        x = F.relu(self.ffn1(x))\n",
        "        x = self.dp1(x)\n",
        "        x = torch.sigmoid(self.ffn2(x))\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qRsl0rGjuy1f"
      },
      "outputs": [],
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABxEDnDNtWPi"
      },
      "source": [
        "### Preparing dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "id": "8JOnkSuhtZmf",
        "outputId": "c5e281cf-2746-4788-906e-9e72d4600c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-409b4c23d178>:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  pd.read_csv('train.csv',engine='python', encoding='utf-8', error_bad_lines=False),\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-409b4c23d178>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"distilbert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m train_dataset, val_dataset = get_dataset(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'python'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-de5407b60feb>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(df, tokenizer, mode)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0min_T_attn_masks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         enc_sent_dict = tokenizer(\n\u001b[0m\u001b[1;32m      8\u001b[0m             \u001b[0msentence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mmax_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2546\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_target_context_manager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_input_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2548\u001b[0;31m             \u001b[0mencodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_one\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mall_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2549\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtext_target\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2550\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_switch_to_target_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m_call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2652\u001b[0m             )\n\u001b[1;32m   2653\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2654\u001b[0;31m             return self.encode_plus(\n\u001b[0m\u001b[1;32m   2655\u001b[0m                 \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m                 \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mencode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   2725\u001b[0m         )\n\u001b[1;32m   2726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2727\u001b[0;31m         return self._encode_plus(\n\u001b[0m\u001b[1;32m   2728\u001b[0m             \u001b[0mtext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2729\u001b[0m             \u001b[0mtext_pair\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtext_pair\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_encode_plus\u001b[0;34m(self, text, text_pair, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    498\u001b[0m     ) -> BatchEncoding:\n\u001b[1;32m    499\u001b[0m         \u001b[0mbatched_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_pair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtext_pair\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 500\u001b[0;31m         batched_output = self._batch_encode_plus(\n\u001b[0m\u001b[1;32m    501\u001b[0m             \u001b[0mbatched_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    502\u001b[0m             \u001b[0mis_split_into_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_split_into_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_fast.py\u001b[0m in \u001b[0;36m_batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose)\u001b[0m\n\u001b[1;32m    426\u001b[0m         )\n\u001b[1;32m    427\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         encodings = self._tokenizer.encode_batch(\n\u001b[0m\u001b[1;32m    429\u001b[0m             \u001b[0mbatch_text_or_text_pairs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0madd_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "train_dataset, val_dataset = get_dataset(\n",
        "        pd.read_csv('train.csv',engine='python', encoding='utf-8', error_bad_lines=False),\n",
        "    tokenizer = tokenizer,\n",
        "    mode = 'train'\n",
        ")\n",
        "\n",
        "batch_size = 8\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size = batch_size,\n",
        "    sampler = RandomSampler(train_dataset)\n",
        ")\n",
        "val_dataloader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size = batch_size,\n",
        "    sampler = SequentialSampler(val_dataset)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cyB9GvGKzZL5",
        "outputId": "f95f0eb7-e73a-4a2d-ec94-37b9e9e49cda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nopft_zZtfow"
      },
      "source": [
        "### Preparing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BnKHjRi7th3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "92b54230e4f947b0873f40f7847a190c",
            "f30b100846fd4aaca1ed17757b67032c",
            "f0d1c2f720f0461d8ec72a0d3ad046f0",
            "c6c3d763b6c24e529fd7b1323b210acd",
            "c9b04c57483246b2a84264c8b5ac8c47",
            "692d6d4390e846faa55d7fac69614917",
            "58080154ea0a431d8b66f3dbeb21ff76",
            "5da2961f283240018316a39ed29829f5",
            "9cbacfea451941df87616f496a469829",
            "07c82a9edfb3447aae80c964e5c7846f",
            "6ed03f4f1541443583bbca9bb5e5e8da"
          ]
        },
        "outputId": "c7ce9430-f71d-49c7-c8d8-e271b8f1265b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92b54230e4f947b0873f40f7847a190c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = MultiTaskClassifier(100, 6).to(device)\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
        "criterion = nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Kra8f_RtzB7"
      },
      "source": [
        "### Training & Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1nXA0jZVt1Ys",
        "outputId": "780a2d97-14a5-4b8f-bd6a-0ec014494bd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 6 ========\n",
            "Training...\n",
            "  Batch 1,000  of  1,436.    Elapsed: 0:03:58. Loss: 0.04602\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:05:43\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.06\n",
            "  Validation took: 0:00:30\n",
            "  Accuracy: 0.95\n",
            "  Accuracy: 0.99\n",
            "  Accuracy: 0.98\n",
            "  Accuracy: 1.00\n",
            "  Accuracy: 0.96\n",
            "  Accuracy: 0.99\n",
            "  Macro F1-score: 0.87\n",
            "  Macro F1-score: 0.72\n",
            "  Macro F1-score: 0.90\n",
            "  Macro F1-score: 0.50\n",
            "  Macro F1-score: 0.84\n",
            "  Macro F1-score: 0.63\n",
            "  Weighted F1-score: 0.95\n",
            "  Weighted F1-score: 0.98\n",
            "  Weighted F1-score: 0.98\n",
            "  Weighted F1-score: 0.99\n",
            "  Weighted F1-score: 0.96\n",
            "  Weighted F1-score: 0.99\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.96      0.97      2566\n",
            "         1.0       0.72      0.82      0.77       306\n",
            "\n",
            "    accuracy                           0.95      2872\n",
            "   macro avg       0.85      0.89      0.87      2872\n",
            "weighted avg       0.95      0.95      0.95      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      2832\n",
            "         1.0       0.46      0.45      0.46        40\n",
            "\n",
            "    accuracy                           0.99      2872\n",
            "   macro avg       0.73      0.72      0.72      2872\n",
            "weighted avg       0.98      0.99      0.98      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      2704\n",
            "         1.0       0.80      0.83      0.81       168\n",
            "\n",
            "    accuracy                           0.98      2872\n",
            "   macro avg       0.89      0.91      0.90      2872\n",
            "weighted avg       0.98      0.98      0.98      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      2858\n",
            "         1.0       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           1.00      2872\n",
            "   macro avg       0.50      0.50      0.50      2872\n",
            "weighted avg       0.99      1.00      0.99      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.97      0.98      2716\n",
            "         1.0       0.60      0.88      0.71       156\n",
            "\n",
            "    accuracy                           0.96      2872\n",
            "   macro avg       0.79      0.92      0.84      2872\n",
            "weighted avg       0.97      0.96      0.96      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99      2836\n",
            "         1.0       0.75      0.17      0.27        36\n",
            "\n",
            "    accuracy                           0.99      2872\n",
            "   macro avg       0.87      0.58      0.63      2872\n",
            "weighted avg       0.99      0.99      0.99      2872\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2469   97]\n",
            " [  54  252]]\n",
            "[[2811   21]\n",
            " [  22   18]]\n",
            "[[2668   36]\n",
            " [  28  140]]\n",
            "[[2858    0]\n",
            " [  14    0]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[2623   93]\n",
            " [  19  137]]\n",
            "[[2834    2]\n",
            " [  30    6]]\n",
            "\n",
            "======== Epoch 2 / 6 ========\n",
            "Training...\n",
            "  Batch 1,000  of  1,436.    Elapsed: 0:04:02. Loss: 0.03690\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:05:48\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.07\n",
            "  Validation took: 0:00:30\n",
            "  Accuracy: 0.95\n",
            "  Accuracy: 0.99\n",
            "  Accuracy: 0.98\n",
            "  Accuracy: 1.00\n",
            "  Accuracy: 0.97\n",
            "  Accuracy: 0.99\n",
            "  Macro F1-score: 0.87\n",
            "  Macro F1-score: 0.69\n",
            "  Macro F1-score: 0.91\n",
            "  Macro F1-score: 0.50\n",
            "  Macro F1-score: 0.86\n",
            "  Macro F1-score: 0.66\n",
            "  Weighted F1-score: 0.95\n",
            "  Weighted F1-score: 0.99\n",
            "  Weighted F1-score: 0.98\n",
            "  Weighted F1-score: 0.99\n",
            "  Weighted F1-score: 0.97\n",
            "  Weighted F1-score: 0.99\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.97      0.97      2566\n",
            "         1.0       0.74      0.82      0.78       306\n",
            "\n",
            "    accuracy                           0.95      2872\n",
            "   macro avg       0.86      0.89      0.87      2872\n",
            "weighted avg       0.95      0.95      0.95      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99      2832\n",
            "         1.0       0.65      0.28      0.39        40\n",
            "\n",
            "    accuracy                           0.99      2872\n",
            "   macro avg       0.82      0.64      0.69      2872\n",
            "weighted avg       0.99      0.99      0.99      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      2704\n",
            "         1.0       0.85      0.82      0.83       168\n",
            "\n",
            "    accuracy                           0.98      2872\n",
            "   macro avg       0.92      0.91      0.91      2872\n",
            "weighted avg       0.98      0.98      0.98      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      2858\n",
            "         1.0       0.00      0.00      0.00        14\n",
            "\n",
            "    accuracy                           1.00      2872\n",
            "   macro avg       0.50      0.50      0.50      2872\n",
            "weighted avg       0.99      1.00      0.99      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.98      0.98      2716\n",
            "         1.0       0.67      0.81      0.73       156\n",
            "\n",
            "    accuracy                           0.97      2872\n",
            "   macro avg       0.83      0.89      0.86      2872\n",
            "weighted avg       0.97      0.97      0.97      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99      2836\n",
            "         1.0       0.67      0.22      0.33        36\n",
            "\n",
            "    accuracy                           0.99      2872\n",
            "   macro avg       0.83      0.61      0.66      2872\n",
            "weighted avg       0.99      0.99      0.99      2872\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2479   87]\n",
            " [  56  250]]\n",
            "[[2826    6]\n",
            " [  29   11]]\n",
            "[[2679   25]\n",
            " [  30  138]]\n",
            "[[2858    0]\n",
            " [  14    0]]\n",
            "[[2654   62]\n",
            " [  30  126]]\n",
            "[[2832    4]\n",
            " [  28    8]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 3 / 6 ========\n",
            "Training...\n",
            "  Batch 1,000  of  1,436.    Elapsed: 0:04:02. Loss: 0.02868\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 0:05:48\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.08\n",
            "  Validation took: 0:00:30\n",
            "  Accuracy: 0.96\n",
            "  Accuracy: 0.98\n",
            "  Accuracy: 0.98\n",
            "  Accuracy: 1.00\n",
            "  Accuracy: 0.97\n",
            "  Accuracy: 0.99\n",
            "  Macro F1-score: 0.89\n",
            "  Macro F1-score: 0.73\n",
            "  Macro F1-score: 0.90\n",
            "  Macro F1-score: 0.57\n",
            "  Macro F1-score: 0.86\n",
            "  Macro F1-score: 0.71\n",
            "  Weighted F1-score: 0.96\n",
            "  Weighted F1-score: 0.98\n",
            "  Weighted F1-score: 0.98\n",
            "  Weighted F1-score: 0.99\n",
            "  Weighted F1-score: 0.97\n",
            "  Weighted F1-score: 0.99\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.98      0.98      2566\n",
            "         1.0       0.80      0.80      0.80       306\n",
            "\n",
            "    accuracy                           0.96      2872\n",
            "   macro avg       0.89      0.89      0.89      2872\n",
            "weighted avg       0.96      0.96      0.96      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      2832\n",
            "         1.0       0.40      0.57      0.47        40\n",
            "\n",
            "    accuracy                           0.98      2872\n",
            "   macro avg       0.70      0.78      0.73      2872\n",
            "weighted avg       0.99      0.98      0.98      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      2704\n",
            "         1.0       0.83      0.79      0.81       168\n",
            "\n",
            "    accuracy                           0.98      2872\n",
            "   macro avg       0.91      0.89      0.90      2872\n",
            "weighted avg       0.98      0.98      0.98      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      2858\n",
            "         1.0       1.00      0.07      0.13        14\n",
            "\n",
            "    accuracy                           1.00      2872\n",
            "   macro avg       1.00      0.54      0.57      2872\n",
            "weighted avg       1.00      1.00      0.99      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.99      0.99      2716\n",
            "         1.0       0.75      0.72      0.73       156\n",
            "\n",
            "    accuracy                           0.97      2872\n",
            "   macro avg       0.87      0.85      0.86      2872\n",
            "weighted avg       0.97      0.97      0.97      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      0.99      2836\n",
            "         1.0       0.69      0.31      0.42        36\n",
            "\n",
            "    accuracy                           0.99      2872\n",
            "   macro avg       0.84      0.65      0.71      2872\n",
            "weighted avg       0.99      0.99      0.99      2872\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2504   62]\n",
            " [  62  244]]\n",
            "[[2798   34]\n",
            " [  17   23]]\n",
            "[[2676   28]\n",
            " [  35  133]]\n",
            "[[2858    0]\n",
            " [  13    1]]\n",
            "[[2679   37]\n",
            " [  44  112]]\n",
            "[[2831    5]\n",
            " [  25   11]]\n",
            "\n",
            "======== Epoch 4 / 6 ========\n",
            "Training...\n",
            "  Batch 1,000  of  1,436.    Elapsed: 0:04:02. Loss: 0.02187\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:05:48\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.08\n",
            "  Validation took: 0:00:30\n",
            "  Accuracy: 0.96\n",
            "  Accuracy: 0.98\n",
            "  Accuracy: 0.98\n",
            "  Accuracy: 1.00\n",
            "  Accuracy: 0.97\n",
            "  Accuracy: 0.99\n",
            "  Macro F1-score: 0.89\n",
            "  Macro F1-score: 0.75\n",
            "  Macro F1-score: 0.90\n",
            "  Macro F1-score: 0.57\n",
            "  Macro F1-score: 0.85\n",
            "  Macro F1-score: 0.74\n",
            "  Weighted F1-score: 0.96\n",
            "  Weighted F1-score: 0.98\n",
            "  Weighted F1-score: 0.98\n",
            "  Weighted F1-score: 0.99\n",
            "  Weighted F1-score: 0.97\n",
            "  Weighted F1-score: 0.99\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.97      0.98      2566\n",
            "         1.0       0.79      0.82      0.80       306\n",
            "\n",
            "    accuracy                           0.96      2872\n",
            "   macro avg       0.88      0.90      0.89      2872\n",
            "weighted avg       0.96      0.96      0.96      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.99      0.99      2832\n",
            "         1.0       0.40      0.68      0.50        40\n",
            "\n",
            "    accuracy                           0.98      2872\n",
            "   macro avg       0.70      0.83      0.75      2872\n",
            "weighted avg       0.99      0.98      0.98      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      2704\n",
            "         1.0       0.84      0.79      0.81       168\n",
            "\n",
            "    accuracy                           0.98      2872\n",
            "   macro avg       0.91      0.89      0.90      2872\n",
            "weighted avg       0.98      0.98      0.98      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      2858\n",
            "         1.0       1.00      0.07      0.13        14\n",
            "\n",
            "    accuracy                           1.00      2872\n",
            "   macro avg       1.00      0.54      0.57      2872\n",
            "weighted avg       1.00      1.00      0.99      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.98      0.98      2716\n",
            "         1.0       0.72      0.71      0.71       156\n",
            "\n",
            "    accuracy                           0.97      2872\n",
            "   macro avg       0.85      0.85      0.85      2872\n",
            "weighted avg       0.97      0.97      0.97      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      1.00      2836\n",
            "         1.0       0.76      0.36      0.49        36\n",
            "\n",
            "    accuracy                           0.99      2872\n",
            "   macro avg       0.88      0.68      0.74      2872\n",
            "weighted avg       0.99      0.99      0.99      2872\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2499   67]\n",
            " [  56  250]]\n",
            "[[2791   41]\n",
            " [  13   27]]\n",
            "[[2678   26]\n",
            " [  36  132]]\n",
            "[[2858    0]\n",
            " [  13    1]]\n",
            "[[2672   44]\n",
            " [  45  111]]\n",
            "[[2832    4]\n",
            " [  23   13]]\n",
            "\n",
            "======== Epoch 5 / 6 ========\n",
            "Training...\n",
            "  Batch 1,000  of  1,436.    Elapsed: 0:04:02. Loss: 0.01884\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:05:48\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.08\n",
            "  Validation took: 0:00:30\n",
            "  Accuracy: 0.95\n",
            "  Accuracy: 0.99\n",
            "  Accuracy: 0.98\n",
            "  Accuracy: 1.00\n",
            "  Accuracy: 0.97\n",
            "  Accuracy: 0.99\n",
            "  Macro F1-score: 0.88\n",
            "  Macro F1-score: 0.76\n",
            "  Macro F1-score: 0.91\n",
            "  Macro F1-score: 0.57\n",
            "  Macro F1-score: 0.85\n",
            "  Macro F1-score: 0.76\n",
            "  Weighted F1-score: 0.96\n",
            "  Weighted F1-score: 0.99\n",
            "  Weighted F1-score: 0.98\n",
            "  Weighted F1-score: 0.99\n",
            "  Weighted F1-score: 0.97\n",
            "  Weighted F1-score: 0.99\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.97      0.97      2566\n",
            "         1.0       0.76      0.83      0.79       306\n",
            "\n",
            "    accuracy                           0.95      2872\n",
            "   macro avg       0.87      0.90      0.88      2872\n",
            "weighted avg       0.96      0.95      0.96      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      2832\n",
            "         1.0       0.48      0.60      0.53        40\n",
            "\n",
            "    accuracy                           0.99      2872\n",
            "   macro avg       0.74      0.80      0.76      2872\n",
            "weighted avg       0.99      0.99      0.99      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      2704\n",
            "         1.0       0.87      0.78      0.82       168\n",
            "\n",
            "    accuracy                           0.98      2872\n",
            "   macro avg       0.93      0.89      0.91      2872\n",
            "weighted avg       0.98      0.98      0.98      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      2858\n",
            "         1.0       1.00      0.07      0.13        14\n",
            "\n",
            "    accuracy                           1.00      2872\n",
            "   macro avg       1.00      0.54      0.57      2872\n",
            "weighted avg       1.00      1.00      0.99      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.98      0.98      2716\n",
            "         1.0       0.72      0.72      0.72       156\n",
            "\n",
            "    accuracy                           0.97      2872\n",
            "   macro avg       0.85      0.85      0.85      2872\n",
            "weighted avg       0.97      0.97      0.97      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      1.00      2836\n",
            "         1.0       0.68      0.42      0.52        36\n",
            "\n",
            "    accuracy                           0.99      2872\n",
            "   macro avg       0.84      0.71      0.76      2872\n",
            "weighted avg       0.99      0.99      0.99      2872\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2487   79]\n",
            " [  52  254]]\n",
            "[[2806   26]\n",
            " [  16   24]]\n",
            "[[2685   19]\n",
            " [  37  131]]\n",
            "[[2858    0]\n",
            " [  13    1]]\n",
            "[[2673   43]\n",
            " [  43  113]]\n",
            "[[2829    7]\n",
            " [  21   15]]\n",
            "\n",
            "======== Epoch 6 / 6 ========\n",
            "Training...\n",
            "  Batch 1,000  of  1,436.    Elapsed: 0:04:02. Loss: 0.01583\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:05:48\n",
            "\n",
            "Running Validation...\n",
            "  Validation Loss: 0.08\n",
            "  Validation took: 0:00:30\n",
            "  Accuracy: 0.95\n",
            "  Accuracy: 0.99\n",
            "  Accuracy: 0.98\n",
            "  Accuracy: 1.00\n",
            "  Accuracy: 0.97\n",
            "  Accuracy: 0.99\n",
            "  Macro F1-score: 0.88\n",
            "  Macro F1-score: 0.74\n",
            "  Macro F1-score: 0.91\n",
            "  Macro F1-score: 0.57\n",
            "  Macro F1-score: 0.85\n",
            "  Macro F1-score: 0.76\n",
            "  Weighted F1-score: 0.95\n",
            "  Weighted F1-score: 0.99\n",
            "  Weighted F1-score: 0.98\n",
            "  Weighted F1-score: 0.99\n",
            "  Weighted F1-score: 0.97\n",
            "  Weighted F1-score: 0.99\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.96      0.97      2566\n",
            "         1.0       0.74      0.85      0.79       306\n",
            "\n",
            "    accuracy                           0.95      2872\n",
            "   macro avg       0.86      0.91      0.88      2872\n",
            "weighted avg       0.96      0.95      0.95      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      2832\n",
            "         1.0       0.50      0.47      0.49        40\n",
            "\n",
            "    accuracy                           0.99      2872\n",
            "   macro avg       0.75      0.73      0.74      2872\n",
            "weighted avg       0.99      0.99      0.99      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      0.99      0.99      2704\n",
            "         1.0       0.86      0.80      0.83       168\n",
            "\n",
            "    accuracy                           0.98      2872\n",
            "   macro avg       0.92      0.89      0.91      2872\n",
            "weighted avg       0.98      0.98      0.98      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      1.00      1.00      2858\n",
            "         1.0       1.00      0.07      0.13        14\n",
            "\n",
            "    accuracy                           1.00      2872\n",
            "   macro avg       1.00      0.54      0.57      2872\n",
            "weighted avg       1.00      1.00      0.99      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.98      0.99      0.98      2716\n",
            "         1.0       0.75      0.70      0.72       156\n",
            "\n",
            "    accuracy                           0.97      2872\n",
            "   macro avg       0.86      0.84      0.85      2872\n",
            "weighted avg       0.97      0.97      0.97      2872\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.99      1.00      1.00      2836\n",
            "         1.0       0.68      0.42      0.52        36\n",
            "\n",
            "    accuracy                           0.99      2872\n",
            "   macro avg       0.84      0.71      0.76      2872\n",
            "weighted avg       0.99      0.99      0.99      2872\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2473   93]\n",
            " [  47  259]]\n",
            "[[2813   19]\n",
            " [  21   19]]\n",
            "[[2682   22]\n",
            " [  34  134]]\n",
            "[[2858    0]\n",
            " [  13    1]]\n",
            "[[2679   37]\n",
            " [  47  109]]\n",
            "[[2829    7]\n",
            " [  21   15]]\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:38:09 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "epochs = 6\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                           num_warmup_steps = 0,\n",
        "                                           num_training_steps = total_steps)\n",
        "\n",
        "\n",
        "training_stats = []\n",
        "total_t0 = time.time()\n",
        "\n",
        "best_val_loss = 1e8\n",
        "true_labels = val_dataset[:][2].numpy()\n",
        "\n",
        "for epoch_i in range(0, epochs):\n",
        "\n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 1000 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}. Loss: {:.5f}'.format(step, len(train_dataloader), elapsed, total_train_loss/step))\n",
        "\n",
        "        b_in_T            = batch[0].to(device)\n",
        "        b_in_T_attn_masks = batch[1].to(device)\n",
        "        b_labels          = batch[2].to(device)\n",
        "        \n",
        "        model.zero_grad()\n",
        "\n",
        "        logits = model(b_in_T, b_in_T_attn_masks)\n",
        "        loss = criterion(logits, b_labels)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
        "\n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "\n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    pred_labels = np.empty((0,6))\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in val_dataloader:\n",
        "        \n",
        "        b_in_T            = batch[0].to(device)\n",
        "        b_in_T_attn_masks = batch[1].to(device)\n",
        "        b_labels          = batch[2].to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_in_T, b_in_T_attn_masks)\n",
        "            loss = criterion(logits, b_labels)\n",
        "\n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        pred_labels = np.concatenate((pred_labels, logits), axis=0)\n",
        "\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(val_dataloader)\n",
        "\n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "\n",
        "    pred_labels = np.array([[int(x >= 0.25) for x in pred_labels[:,i]] for i  in range(6)]).transpose()\n",
        "\n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "#     Report the final accuracy, f1-score for this validation run.\n",
        "    for i in range(6):\n",
        "        print(\"  Accuracy: {0:.2f}\".format(accuracy_score(true_labels[:,i], pred_labels[:,i])))\n",
        "\n",
        "    for i in range(6):\n",
        "        print(\"  Macro F1-score: {0:.2f}\".format(f1_score(true_labels[:,i], pred_labels[:,i], average='macro')))\n",
        "\n",
        "    for i in range(6):\n",
        "        print(\"  Weighted F1-score: {0:.2f}\".format(f1_score(true_labels[:,i], pred_labels[:,i], average='weighted')))\n",
        "\n",
        "    print('Classification Report:')\n",
        "    for i in range(6):\n",
        "        print(classification_report(true_labels[:,i], pred_labels[:,i]))\n",
        "\n",
        "    print('Confusion Matrix:')\n",
        "    for i in range(6):\n",
        "        print(confusion_matrix(true_labels[:,i], pred_labels[:,i]))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'training_loss': avg_train_loss,\n",
        "            'val_loss': avg_val_loss,\n",
        "            'val_accuracy': np.mean([accuracy_score(true_labels[:,i], pred_labels[:,i]) for i in range(6)]),\n",
        "            'val_macro_f1': np.mean([f1_score(true_labels[:,i], pred_labels[:,i], average='macro') for i in range(6)]),\n",
        "            'val_weighted_f1': np.mean([f1_score(true_labels[:,i], pred_labels[:,i], average='weighted') for i in range(6)]),\n",
        "            'training_time': training_time,\n",
        "            'val_tim': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "    model_path = 'model_state_dict_'+str(epoch_i)+'.pt'\n",
        "    torch.save(model.state_dict(), model_path)\n",
        "\n",
        "print(\"\")\n",
        "stats_path = 'training_stats_pickle'\n",
        "pd.DataFrame(training_stats).to_pickle(stats_path)\n",
        "\n",
        "print(\"Training complete!\")\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dfff=pd.read_csv('test.csv',engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "test_labels_dfff=pd.read_csv('test_labels.csv',engine='python', encoding='utf-8', error_bad_lines=False)\n",
        "train_dfff=pd.read_csv('train.csv',engine='python', encoding='utf-8', error_bad_lines=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51RmMDLogxKs",
        "outputId": "4d0776a8-eae4-4e57-e914-34cf48124760"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-0040d0e7227b>:1: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  test_dfff=pd.read_csv('test.csv',engine='python', encoding='utf-8', error_bad_lines=False)\n",
            "<ipython-input-21-0040d0e7227b>:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  test_labels_dfff=pd.read_csv('test_labels.csv',engine='python', encoding='utf-8', error_bad_lines=False)\n",
            "<ipython-input-21-0040d0e7227b>:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  train_dfff=pd.read_csv('train.csv',engine='python', encoding='utf-8', error_bad_lines=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset, _ = get_dataset(\n",
        "       pd.merge(test_dfff, test_labels_dfff, on='id'),\n",
        "    tokenizer = tokenizer\n",
        ")\n",
        "\n",
        "batch_size = 8\n",
        "test_dataloader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size = batch_size,\n",
        "    sampler = RandomSampler(test_dataset)\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_81UDOHbw1A",
        "outputId": "93d839b4-865c-459e-acd8-48abdd6203b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2364: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text Input:  torch.Size([153164, 300])\n",
            "Text Input Attention:  torch.Size([153164, 300])\n",
            "Labels:  torch.Size([153164, 6])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate data for one epoch\n",
        "true_labels = test_dataset[:][2].numpy()\n",
        "\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    b_in_T            = batch[0].to(device)\n",
        "    b_in_T_attn_masks = batch[1].to(device)\n",
        "    b_labels          = batch[2].to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(b_in_T, b_in_T_attn_masks)\n",
        "        loss = criterion(logits, b_labels)\n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    pred_labels = np.concatenate((pred_labels, logits), axis=0)\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_test_loss = total_eval_loss / len(test_dataloader)\n",
        "# Measure how long the validation run took.\n",
        "test_time = format_time(time.time() - t0)\n",
        "pred_labels = np.array([[int(x >= 0.25) for x in pred_labels[:,i]] for i  in range(6)]).transpose()\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_test_loss))\n",
        "print(\"  Test took: {:}\".format(test_time))\n",
        "  #Report the final accuracy, f1-score for this validation run.\n",
        "for i in range(6):\n",
        "    print(\"  Accuracy: {0:.2f}\".format(accuracy_score(true_labels[:,i], pred_labels[:,i])))\n",
        "for i in range(6):\n",
        "    print(\"  Macro F1-score: {0:.2f}\".format(f1_score(true_labels[:,i], pred_labels[:,i], average='macro')))\n",
        "for i in range(6):\n",
        "    print(\"  Weighted F1-score: {0:.2f}\".format(f1_score(true_labels[:,i], pred_labels[:,i], average='weighted')))\n",
        "print('Classification Report:')\n",
        "for i in range(6):\n",
        "    print(classification_report(true_labels[:,i], pred_labels[:,i]))\n",
        "print('Confusion Matrix:')\n",
        "for i in range(6):\n",
        "    print(confusion_matrix(true_labels[:,i], pred_labels[:,i]))"
      ],
      "metadata": {
        "id": "DFavHKjWc9Km"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "92b54230e4f947b0873f40f7847a190c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f30b100846fd4aaca1ed17757b67032c",
              "IPY_MODEL_f0d1c2f720f0461d8ec72a0d3ad046f0",
              "IPY_MODEL_c6c3d763b6c24e529fd7b1323b210acd"
            ],
            "layout": "IPY_MODEL_c9b04c57483246b2a84264c8b5ac8c47"
          }
        },
        "f30b100846fd4aaca1ed17757b67032c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_692d6d4390e846faa55d7fac69614917",
            "placeholder": "​",
            "style": "IPY_MODEL_58080154ea0a431d8b66f3dbeb21ff76",
            "value": "Downloading pytorch_model.bin: 100%"
          }
        },
        "f0d1c2f720f0461d8ec72a0d3ad046f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5da2961f283240018316a39ed29829f5",
            "max": 267967963,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cbacfea451941df87616f496a469829",
            "value": 267967963
          }
        },
        "c6c3d763b6c24e529fd7b1323b210acd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07c82a9edfb3447aae80c964e5c7846f",
            "placeholder": "​",
            "style": "IPY_MODEL_6ed03f4f1541443583bbca9bb5e5e8da",
            "value": " 268M/268M [00:02&lt;00:00, 121MB/s]"
          }
        },
        "c9b04c57483246b2a84264c8b5ac8c47": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "692d6d4390e846faa55d7fac69614917": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58080154ea0a431d8b66f3dbeb21ff76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5da2961f283240018316a39ed29829f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cbacfea451941df87616f496a469829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "07c82a9edfb3447aae80c964e5c7846f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ed03f4f1541443583bbca9bb5e5e8da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}